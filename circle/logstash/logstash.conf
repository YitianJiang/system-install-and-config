input {
  kafka {
    bootstrap_servers => "kafka:9092" #kafka服务器地址
    topics => "business"
    codec => "json" #写入的时候使用json编码，因为logstash收集后会转换成json格式
    group_id => "business" 
    consumer_threads => 1
    decorate_events => true
    type => "business"
  }
  kafka {
    bootstrap_servers => "kafka:9092" #kafka服务器地址
    topics => "api"
    codec => "json" #写入的时候使用json编码，因为logstash收集后会转换成json格式
    group_id => "api" 
    consumer_threads => 1
    decorate_events => true
    type => "api"
  }
  jdbc {  #参考 https://blog.csdn.net/u013850277/article/details/88753348
    jdbc_connection_string => "jdbc:mysql://mysql/circle?useSSL=false"
    jdbc_user => "root"
    jdbc_password =>"root"
    jdbc_driver_library => "/mysql-connector-java-8.0.15.jar"
    jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
    jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    statement_filepath => "/jdbc.sql"
    type => "jdbc"
  }
}
output {
  if [type] == "business" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "circle-%{type}-%{+YYYY.MM.dd}"
    }
    file {
      codec => json
      path => "/usr/share/logstash/business"
    }
  }
  if [type] == "api" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "circle-%{type}-%{+YYYY.MM.dd}"
    }
    file {
      codec => json
      path => "/usr/share/logstash/api"
    }
  }
  if [type] == "jdbc" {
    hosts => ["elasticsearch:9200"]
    index => "jdbc"
    document_id => "%{id}"
  }
}    
